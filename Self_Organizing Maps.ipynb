{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#                                            **Self Organising Maps**"
      ],
      "metadata": {
        "id": "NYsMqOwQ_lOa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Introduction**\n"
      ],
      "metadata": {
        "id": "qLZEWNnmAFTh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Theory**"
      ],
      "metadata": {
        "id": "vmifoJpiATRK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Self-Organising Feature Map (SOM) is a competitive learning algorithm proposed by Teuvo Kohonen in 1988.\n",
        "The SOM feature map comprises of a grid of inter-connected neurons.\n",
        "\n",
        "The SOM is perfectly topology preserving which means that if the dimensionality of the input and the feature map correspond, then the relative ordering of the inputs is preserved by ordering in the neurons, so that neurons that are close together represent inputs that are close together, while neurons that are far apart represent inputs that are far apart.\n",
        "\n",
        "Algorithm Pseudocode:\n",
        "\n",
        "\n",
        "\n",
        "1.   Initialisation\n",
        "    *   Choose a size (number of neurons) and number of dimensions d for the map.\n",
        "    *   Choose random values for the weight vectors so that they are all different.\n",
        "\n",
        "2.   Learning\n",
        "\n",
        "    – repeat:\n",
        "        * for each datapoint:\n",
        "            * Select the best-matching neuron nb using the minimum Euclidean distance\n",
        "between the weights and the input,\n",
        "\n",
        "            nb = minjkx − wTj k.\n",
        "            * Update the weight vector of the best-matching node using:\n",
        "\n",
        "            wTj  wTj + \u0011(t)(x − wTj ),\n",
        "\n",
        "            where \u0011(t) is the learning rate.\n",
        "\n",
        "            * update the weight vector of all other neurons using:\n",
        "\n",
        "            wTj   wTj + \u0011n(t)h(nb, t)(x − wTj ),\n",
        "\n",
        "            where \u0011n(t) is the learning rate for neighbourhood nodes, and h(nb, t) is the neighbourhood function, which decides whether each neuron should be included in the neighbourhood of the winning neuron (so h = 1 for neighbours and h = 0 for non-neighbours)\n",
        "\n",
        "            * reduce the learning rates and adjust the neighbourhood function, typically by \u0011(t+1) = \n",
        "\u0011(t)k/kmax where 0 \u0014 \n",
        " \u0014 1 decides how fast the size decreases, k is the number of iterations the algorithm has been running for, and kmax\n",
        "is when you want the learning to stop. The same equation is used for both learning rates (\u0011, \u0011n) and the neighbourhood function h(nb, t).\n",
        "\n",
        "    – until the map stops changing or some maximum number of iterations is exceeded\n",
        "\n",
        "3. Usage:\n",
        "\n",
        "    – for each test point:\n",
        "    * select the best-matching neuron nb using the minimum Euclidean distance between the weights and the input:\n",
        "\n",
        "    nb = minjkx − wTj k"
      ],
      "metadata": {
        "id": "MXmMP73vU27L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Message Box**\n",
        "\n",
        "Remaining- \n",
        "1. Reading csv data and standardization\n",
        "2. Integration and Testing\n",
        "3. Documentation\n",
        "4. Deciding optimal lattice size and other discussions"
      ],
      "metadata": {
        "id": "aDRsar32Rnri"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Update in code \n",
        "1. Standardized the dataset \n",
        "2. Initially the lattice neurons were initialized randomly with the same number due to the same seed used to initialize all the neurons so I changed the code which will randomly generate weights for neuron with different seeds .\n",
        "3. Now we can experiment with different lattice sizes along with learning rate , choosing the initial distribution for neurons and decay function of learning rate.\n"
      ],
      "metadata": {
        "id": "J-IGHh_DcODc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Source Code**"
      ],
      "metadata": {
        "id": "aAYuy4WC_Z41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile neuron.cpp\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <string>\n",
        "#include <fstream>\n",
        "#include <sstream>\n",
        "#include <random>\n",
        "#include <cstdlib>\n",
        "#include <time.h>\n",
        "using namespace std;\n",
        "\n",
        "//1. Class Country_Stats to store the data about the countries\n",
        "class Country_Stats\n",
        "{\n",
        "  public:\n",
        "\n",
        "  string country; //Name of the country\n",
        "  vector<double> stats; //stores the 9 attributes\n",
        "  void print_country()\n",
        "  {\n",
        "      cout<< country <<\" \";\n",
        "      for(auto x:stats) cout<< x<<\" \";\n",
        "      cout<<endl;\n",
        "  }\n",
        "};\n",
        "\n",
        "//2. Neurons are treated as vectors of number of dimensions equal to the number of features in the input data\n",
        "class Neuron\n",
        "{\n",
        "    public:\n",
        "\n",
        "    int weight_size; //equal to number of features\n",
        "    vector<double>weights; //weights vector\n",
        "    pair<int,int>coordinate; //location of neuron in lattice\n",
        "\n",
        "    void set_neuron_coordinates(const int weight_size,int x_cord,int y_cord)\n",
        "    {\n",
        "        this->weight_size=weight_size;\n",
        "        this->weights.resize(weight_size,0.0);\n",
        "        this->coordinate.first=x_cord;\n",
        "        this->coordinate.second=y_cord;\n",
        "        return;\n",
        "    }\n",
        "    vector<double> Initialize_neuron_normal()\n",
        "    {\n",
        "        /*\n",
        "        We don't need mean or std of the features since we are standardizing the data\n",
        "        our feature values will follow standard normal distribution with mean=0 and std=1\n",
        "        */\n",
        "      \n",
        "       random_device rd{};\n",
        "       mt19937 gen{rd()};\n",
        " \n",
        "        // values near the mean are the most likely\n",
        "        // standard deviation affects the dispersion of generated values from the mean\n",
        "        for (int i=0;i<this->weight_size;i++){\n",
        "            normal_distribution<double>dist{0,1};\n",
        "            weights[i]=dist(gen);\n",
        "        }\n",
        "        return weights;\n",
        "    }\n",
        "    //Randomly Initialize neuron weights\n",
        "    void initialize_neuron_random(const int x,const int y)\n",
        "    {\n",
        "      unsigned seed = 10*(x+1)+y;\n",
        "      srand(seed);\n",
        "        \n",
        "        for (int i=0;i<this->weight_size;i++)\n",
        "        {\n",
        "            \n",
        "            double random_number_oto1= (double)(rand()/(1.0*RAND_MAX));\n",
        "         //   cout<<random_number_oto1<<\"Generated random number\\n\";\n",
        "            //a random number from 0 to 1 is assigned to weights\n",
        "            weights[i]=random_number_oto1;\n",
        "        }\n",
        "        return;\n",
        "    }\n",
        "};\n",
        "\n",
        "//3. A Lattice class to organize the neurons. The SOM algorithm will operate on this\n",
        "class Lattice\n",
        "{\n",
        "  public:\n",
        "\n",
        "    int lattice_length;\n",
        "    int lattice_width;\n",
        "    vector<vector<Neuron>> lattice;\n",
        "    //Constructors\n",
        "    Lattice(){}\n",
        "    Lattice(int length, int width)\n",
        "    {   //set size of lattice if given\n",
        "        lattice_length=length;\n",
        "        lattice_width=width;\n",
        "        lattice.resize(length,vector<Neuron>(width));\n",
        "    }\n",
        "    //Define positions of neurons and initialize their weights\n",
        "    void initialize_Lattice_Neurons(const int number_of_features,string distribution=\"r\")\n",
        "   {\n",
        "       for(int i=0;i<lattice_length;i++)\n",
        "        for(int j=0;j<lattice_width;j++)\n",
        "        {\n",
        "          lattice[i][j].set_neuron_coordinates(number_of_features,i,j);//Set position and size of neurons\n",
        "          if(distribution==\"r\"){\n",
        "            lattice[i][j].initialize_neuron_random(i,j);//Initialize weights\n",
        "          }\n",
        "          else if(distribution==\"n\"){\n",
        "            lattice[i][j].Initialize_neuron_normal();\n",
        "          }\n",
        "          else{\n",
        "            cout<<\"No distribution with that alphabet\\n\";\n",
        "          }\n",
        "         // \n",
        "          ////Initialize weights from normal distribution\n",
        "        }\n",
        "   }\n",
        "   \n",
        "};\n",
        "\n",
        "//4. Contains all the Functions used to implement the SOM Algorithm\n",
        "class Self_Organising_Map\n",
        "{\n",
        "  public:\n",
        "  double learning_rate;//Name is self explanatory\n",
        "  int number_of_epochs;//The number of Iterations for which the Algorithm will run\n",
        "  vector<pair<Neuron,double>>winners;\n",
        "  //Parameterized Constructor\n",
        "  Self_Organising_Map(double lr, int num_epochs)\n",
        "  {\n",
        "    learning_rate=lr;\n",
        "    number_of_epochs=num_epochs;\n",
        "  }\n",
        "\n",
        "  //a. Find Distance between a Neuron's weight vector and a Row vector of Data\n",
        "  double find_neuron_distance(const Neuron& neuron, const Country_Stats &country_stats)\n",
        "  {\n",
        "    double ans=0.0;\n",
        "    int number_of_features= neuron.weight_size;\n",
        "    for(int i=0;i<number_of_features;i++)\n",
        "      ans+= (country_stats.stats[i] -neuron.weights[i])*(country_stats.stats[i] -neuron.weights[i]);\n",
        "    //Return the Euclidean distance\n",
        "    return (double) sqrt(ans);\n",
        "  }\n",
        "  void PrintLattice(const Lattice *SOM)\n",
        "  {\n",
        "    int row=SOM->lattice_length;\n",
        "    int cols=SOM->lattice_width;\n",
        "    for(int i=0;i<row;i++){\n",
        "        for(int j=0;j<cols;j++){\n",
        "            int x_cord=SOM->lattice[i][j].coordinate.first;\n",
        "            int y_cord=SOM->lattice[i][j].coordinate.second;\n",
        "            cout<<\"Coordinates of the neuron \"<<x_cord<<\" \"<<y_cord<<\"\\n\";\n",
        "            for(auto it:SOM->lattice[i][j].weights){\n",
        "                cout<<it<<\" \";\n",
        "            }\n",
        "            cout<<\"\\n\";\n",
        "        }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  //b. Find the Winner Neuron for a given country\n",
        "  pair<Neuron,double> find_winner_neuron(const Lattice * SOM, const Country_Stats &country_stats)\n",
        "  {\n",
        "    //Initialize winner neuron with the first neuron of lattice\n",
        "    Neuron winner=SOM->lattice[0][0];\n",
        "    double min_distance=find_neuron_distance(winner,country_stats);\n",
        "    //For all neurons of the Lattice\n",
        "    for(int i=0;i<SOM->lattice_length;i++)\n",
        "      for(int j=0;j<SOM->lattice_width;j++)\n",
        "      {\n",
        "        double curr_neuron_distance=find_neuron_distance(SOM->lattice[i][j],country_stats);\n",
        "        //If distance of current neuron is less than the winner till now\n",
        "        if(curr_neuron_distance< min_distance)\n",
        "        {\n",
        "          winner=SOM->lattice[i][j];//Declare current neuron as winner\n",
        "          min_distance=curr_neuron_distance;//Update the min distance with new winner disatnce\n",
        "        }\n",
        "      }\n",
        "    return {winner,min_distance};\n",
        "  }\n",
        "\n",
        "  //c. Update the neurons' weights based on its distance(neighborhood) with the winner.\n",
        "  // The more closer a neuron is to the winner, more its weights are affected\n",
        "  void update_neuron_weights(Lattice* SOM, Neuron &winner, const Country_Stats &country_stats)\n",
        "  {\n",
        "    int winnerx=winner.coordinate.first;\n",
        "    int winnery=winner.coordinate.second;\n",
        "    int num_features=winner.weight_size;\n",
        "    //For all neurons of the lattice\n",
        "    for(int neuronx=0;neuronx < SOM->lattice_length;neuronx++)\n",
        "        for(int neurony=0;neurony < SOM->lattice_width;neurony++)\n",
        "        {\n",
        "            //Calculate the distance between the neuron and the winner and the neighborhood function\n",
        "            int d=(neuronx-winnerx)*(neuronx-winnerx) + (neurony-winnery)*(neurony-winnery);\n",
        "            double neighbourhood_function=exp(-pow(d,0.5));\n",
        "            //Update the neuron's weight vector\n",
        "            for(int i=0;i<num_features;i++)\n",
        "            {\n",
        "                // wij = wij(old) + alpha(t) * neighbourhood_finction * (xik - wij(old))\n",
        "                SOM->lattice[neuronx][neurony].weights[i]+= learning_rate*neighbourhood_function*(country_stats.stats[i]- SOM->lattice[neuronx][neurony].weights[i]);\n",
        "            }\n",
        "        }\n",
        "  }\n",
        "  \n",
        "void preprocess_data(vector<Country_Stats>&country_data)\n",
        "{\n",
        "    int number_of_countries=country_data.size();\n",
        "    int number_of_features=country_data[0].stats.size();\n",
        "    vector<double>sum(number_of_features,0.0);\n",
        "    vector<double>std(number_of_features,0.0);\n",
        "    for(int i=0;i<number_of_countries;i++){\n",
        "        for(int j=0;j<number_of_features;j++){\n",
        "            sum[j]+=country_data[i].stats[j];\n",
        "        }\n",
        "    }\n",
        "    for(int i=0;i<number_of_features;i++){\n",
        "        sum[i]=sum[i]/number_of_countries;\n",
        "    }\n",
        "    for(int i=0;i<number_of_countries;i++){\n",
        "        for(int j=0;j<number_of_features;j++){\n",
        "            std[j]+=(country_data[i].stats[j]-sum[j])*(country_data[i].stats[j]-sum[j]);\n",
        "\n",
        "        }\n",
        "    }\n",
        "    for(int i=0;i<number_of_features;i++){\n",
        "        std[i]=std[i]/(number_of_countries-1);\n",
        "    }\n",
        "    for(int i=0;i<number_of_countries;i++){\n",
        "        for(int j=0;j<number_of_features;j++){\n",
        "            if(std[j]==0){\n",
        "                continue;\n",
        "            }\n",
        "            country_data[i].stats[j]=(country_data[i].stats[j]-sum[j])/(std[j]);\n",
        "\n",
        "        }\n",
        "    }\n",
        "    //return country_data;\n",
        "    \n",
        "}\n",
        "  double error(int rows=1){\n",
        "    double distance=0;\n",
        "    for(auto it:winners){\n",
        "      distance+=it.second;\n",
        "    }\n",
        "    distance=distance/rows;\n",
        "    return distance;\n",
        "\n",
        "  }\n",
        "\n",
        "  //d. Change the learning rate based on the number of iterations done till now and the total number of epochs\n",
        "  \n",
        "  double change_learning_rate(const int epochs,const string method=\"d\")//d for decay using formula 1 and l for decay using formula 2\n",
        "  {\n",
        "    if(method==\"d\"){\n",
        "      return (double)((learning_rate*epochs)/(number_of_epochs*1.0));//formula 1\n",
        "    }\n",
        "    else if(method==\"l\"){\n",
        "      return (double)((learning_rate*exp((-epochs)/(number_of_epochs*1.0))));//formula 2\n",
        "    }\n",
        "    else{\n",
        "      cout<<\"No suitable decay chosen hence learning rate not changed\\n\";\n",
        "      return learning_rate;\n",
        "    }\n",
        "    \n",
        "  }\n",
        "  void PrintNeuronweights(const Neuron &neuron)\n",
        "  {\n",
        "    for(auto it:neuron.weights){\n",
        "        cout<<it<<\" \";\n",
        "    }\n",
        "    cout<<'\\n';\n",
        "  }\n",
        "  //e. Integrate all the functionalities and train the Self Organizing Map\n",
        "  void simulate_SOM(Lattice* SOM_lattice,  vector<Country_Stats> & country_data, const int number_of_features,const string dist=\"r\")\n",
        "  {\n",
        "    //Initialize the Lattice of neurons\n",
        "    cout<<\"Starting Simulation\\n\";\n",
        "    preprocess_data(country_data);\n",
        "    SOM_lattice->initialize_Lattice_Neurons(number_of_features,dist);\n",
        "\n",
        "    //PrintLattice(SOM_lattice);\n",
        "    //Repeat for number of epochs (iterations)\n",
        "    int rows=country_data.size();\n",
        "    for(int epoch=1;epoch<=number_of_epochs;epoch++)\n",
        "    {\n",
        "      // for each country\n",
        "      for(int i=0;i<rows;i++)\n",
        "      {\n",
        "        //Find the winner and update the weights of neurons\n",
        "        pair<Neuron,double>p= find_winner_neuron(SOM_lattice,country_data[i]);\n",
        "        //cout<<\"Initial weights of winner\\n\";\n",
        "        //PrintNeuronweights(SOM_lattice->lattice[winner.coordinate.first][winner.coordinate.second]);\n",
        "        winners.push_back(p);\n",
        "        update_neuron_weights(SOM_lattice,p.first,country_data[i]);\n",
        "        //cout<<\"Updated weights of winner\\n\";\n",
        "        //PrintNeuronweights(SOM_lattice->lattice[winner.coordinate.first][winner.coordinate.second]);\n",
        "      }\n",
        "      //Change the learning rate after each epoch\n",
        "      double loss=error(rows);\n",
        "      learning_rate=change_learning_rate(epoch,\"l\");\n",
        "      cout<<\"Current Epoch number #\"<<epoch<<\" Error :\"<<loss<<\" Learning rate changed to ->\"<<learning_rate<<\"\\n\";\n",
        "      winners.clear();\n",
        "    }\n",
        "   // cout<<\"Final lattice weights\\n\";\n",
        "    //PrintLattice(SOM_lattice);\n",
        "  }\n",
        "};\n",
        "\n",
        "int main()\n",
        "{\n",
        "    vector<Country_Stats> country_data;\n",
        "     int number_of_features=9;\n",
        "    // **Reading the data**\n",
        "\n",
        "    fstream fin;\n",
        "    fin.open(\"Country-data-refined.csv\", ios::in);\n",
        "    //Temporary variables to help in reading the file\n",
        "    vector<string> row;\n",
        "    string line, word;\n",
        "    Country_Stats temp_country;\n",
        "    //Consume the first row of headers\n",
        "    getline(fin, line);\n",
        "\n",
        "    while (getline(fin, line))\n",
        "    {   //clear the row variable and store new row of data in it\n",
        "        row.clear();\n",
        "        stringstream s(line);\n",
        "        while (getline(s, word, ','))\n",
        "          row.push_back(word);\n",
        "        //store data in temp_country from row variable\n",
        "        temp_country.country= row[0];\n",
        "        temp_country.stats.clear();\n",
        "        for(int i=1;i<row.size();i++) temp_country.stats.push_back(stod(row[i]));\n",
        "        //push this temp_country in country_data\n",
        "        country_data.push_back(temp_country);\n",
        "    }\n",
        "\n",
        "    //**Action Time**\n",
        "\n",
        "   int proposed_lattice_length=4;\n",
        "   int proposed_lattice_width=4;\n",
        "   //Instantiating\n",
        "   //preprocess_data(country_data);\n",
        "   Lattice *SOM_lattice= new Lattice(proposed_lattice_length,proposed_lattice_width);\n",
        "   Self_Organising_Map *SOM=new Self_Organising_Map(0.5,10);\n",
        "   //Train the Self Organizing Map\n",
        "   SOM->simulate_SOM(SOM_lattice,country_data,number_of_features,\"n\");\n",
        "   Country_Stats worst_country;\n",
        "   worst_country.country=\"Worst Country\";\n",
        "   vector<double>worst_stats{1,0,0,1,0,1,0,0,0};\n",
        "   worst_country.stats=worst_stats;\n",
        "\n",
        "   //Results\n",
        "\n",
        "   pair<Neuron,double>temp = SOM->find_winner_neuron(SOM_lattice,worst_country);\n",
        "   cout<<\"Cluster coordinate of worst countries \"<<temp.first.coordinate.first<<\" \"<<temp.first.coordinate.second<<\"\\n\";\n",
        "   int coord_x_worst=temp.first.coordinate.first;\n",
        "   int coord_y_worst=temp.first.coordinate.second;\n",
        "   vector<string>worst_country_name;\n",
        "   for(auto it:country_data){\n",
        "    pair<Neuron,double>temp = SOM->find_winner_neuron(SOM_lattice,it);\n",
        "    if(temp.first.coordinate.first==coord_x_worst && temp.first.coordinate.second==coord_y_worst){\n",
        "      worst_country_name.push_back(it.country);\n",
        "    }\n",
        "\n",
        "   }\n",
        "   //SOM_lattice->initialize_Lattice_Neurons(10);\n",
        "   //SOM->PrintNeuronweights(SOM_lattice->lattice[0][0]);\n",
        "   \n",
        "    cout << \"Hello world!\" << endl;\n",
        "    for(auto it:worst_country_name){\n",
        "      cout<<it<<\"\\n\";\n",
        "    }\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRdnEPjDhKGd",
        "outputId": "d841b178-4ef6-408a-a3e1-00b190992740"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting neuron.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Command to run the source code**"
      ],
      "metadata": {
        "id": "ijSzhLzc_Kqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%script bash\n",
        "\n",
        "g++ neuron.cpp \n",
        "./a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNN5m5HfDFl7",
        "outputId": "6cb874bf-4156-4ad1-c0af-a095db6137b2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Simulation\n",
            "Current Epoch number #1 Error :0.367956 Learning rate changed to ->0.452419\n",
            "Current Epoch number #2 Error :0.294358 Learning rate changed to ->0.370409\n",
            "Current Epoch number #3 Error :0.29312 Learning rate changed to ->0.274406\n",
            "Current Epoch number #4 Error :0.291221 Learning rate changed to ->0.18394\n",
            "Current Epoch number #5 Error :0.286555 Learning rate changed to ->0.111565\n",
            "Current Epoch number #6 Error :0.279868 Learning rate changed to ->0.0612282\n",
            "Current Epoch number #7 Error :0.274548 Learning rate changed to ->0.030405\n",
            "Current Epoch number #8 Error :0.271464 Learning rate changed to ->0.0136619\n",
            "Current Epoch number #9 Error :0.269486 Learning rate changed to ->0.0055545\n",
            "Current Epoch number #10 Error :0.268515 Learning rate changed to ->0.00204339\n",
            "Cluster coordinate of worst countries 1 2\n",
            "Hello world!\n",
            "Cambodia\n",
            "Dominican Republic\n",
            "Paraguay\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changes made :\n",
        "1. I made a function for changing learning rate to change learning rate per epoch\n",
        "2. Created a new function for updating the weights of winner and neighbourhood neuron taken from the paper I was refering to yesterday .\n",
        "3. Practically I think we should initialize our lattice neurons from a particular distribution like normal or uniform but we can leave that for experimentation\n",
        "   \n",
        "   Yes, we'll do that. I had done that randomly just for testing the code as mean and sd vectors were not available."
      ],
      "metadata": {
        "id": "_DyN5RM1X6pU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Features of our Self Organizing Maps are \n",
        "1. Leaky Learning all the neighbours of winner neuron is updated with variable amounts\n",
        "2. Changing Learning Rate with increase in epochs\n"
      ],
      "metadata": {
        "id": "xFUB2Dl1oyJt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding the country which needs the most help \n",
        "\n",
        "The country which would be in dire need of help will have </br>\n",
        "high child mortality(1) </br>\n",
        "very less exports(0) </br>\n",
        "very poor health spending(0) </br>\n",
        "Very much dependent on other countries hence very high import(1)  </br>\n",
        "Low income (0)</br>\n",
        "High inflation(1) </br>\n",
        "Low life_expectancy(0) </br>\n",
        "Due to poor health funding the fertility rate of women will also be very low(0) </br>\n",
        "Very Low GDP(0) </br>\n",
        "Our stats for the most help needed country would be {1,0,0,1,0,1,0,0,0}\n",
        "Using this info we find the winner neuron for this country i.e the cluster coordinate of such countries\n",
        "Then find the winner neuron for the entire country data and find the country which belong to this cluster\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rvuAPGPApO0m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Results \n",
        "The top 3 countries where HELP NGO should focus on are in no particular order\n",
        "1. Cambodia\n",
        "2. Dominican Republic\n",
        "3. Paraguay"
      ],
      "metadata": {
        "id": "BnjTUAGcrYeH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**References**"
      ],
      "metadata": {
        "id": "-o-eVzNjANul"
      }
    }
  ]
}